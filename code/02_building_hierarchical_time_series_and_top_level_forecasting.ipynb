{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90cc6fb",
   "metadata": {},
   "source": [
    "# Project: Predict Future Sales\n",
    "#### Notebook 2 of 4: building hierarchical time series and top level forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6bdecd",
   "metadata": {},
   "source": [
    "In this notebook, we mainly did the following:\n",
    "- Building hierarchical time series for each shop\n",
    "- Forecasting all top level hierachical time series using Facebook Prophet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6935c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from textwrap import wrap\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "from prophet import Prophet\n",
    "import itertools\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "\n",
    "import holidays\n",
    "\n",
    "\n",
    "import hts.functions\n",
    "import collections\n",
    "from hts import HTSRegressor\n",
    "from hts.hierarchy import HierarchyTree\n",
    "\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942686de",
   "metadata": {},
   "source": [
    "# define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8166a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is for hyperparameter tuning to get best hyperparamters of \n",
    "# - changepoint_prior_scale\n",
    "# - seasonality_prior_scacle\n",
    "\n",
    "def get_best_hyperparams(data):   \n",
    "    \n",
    "    default_best_params = {'changepoint_prior_scale': 0.2, 'seasonality_prior_scale': 0.5}\n",
    "    \n",
    "    first_cutoff_date = pd.to_datetime('2014-02-1')\n",
    "    first_nonzero_date = data['y'].ne(0).idxmax()\n",
    "    \n",
    "    # return default_best_params if \n",
    "    # 1. all values are zero\n",
    "    # 2. too many values are zero\n",
    "    if (data['y'] == 0).all() or (first_cutoff_date < first_nonzero_date):\n",
    "        print( first_nonzero_date)\n",
    "        print(\"too many zero values, return default best params\")\n",
    "        return default_best_params\n",
    "    else:\n",
    "        param_grid = {  \n",
    "                'changepoint_prior_scale': [0.01,0.2],\n",
    "                'seasonality_prior_scale': [0.01,0.5 ],\n",
    "        }\n",
    "\n",
    "        # Generate all combinations of parameters\n",
    "        all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "        rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "        # Use cross validation to evaluate all parameters\n",
    "        cutoffs = pd.to_datetime(['2014-02-1', '2015-06-1'])\n",
    "        #cutoffs = pd.to_datetime(['2015-9-1'])\n",
    "        \n",
    "        \n",
    "        for params in all_params:\n",
    "            m = Prophet(**params).fit(data)  # Fit model with given params\n",
    "            df_cv = cross_validation(m, cutoffs=cutoffs, horizon='60 days', parallel=\"processes\")\n",
    "            df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "            rmses.append(df_p['rmse'].values[0])\n",
    "\n",
    "        # Find the best parameters\n",
    "        tuning_results = pd.DataFrame(all_params)\n",
    "        tuning_results['rmse'] = rmses\n",
    "\n",
    "        best_params = all_params[np.argmin(rmses)]\n",
    "        print(best_params)\n",
    "        return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d0ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function is to return the best predictions \n",
    "# step1: get best hyperparameters by calling funciotn 'get_best_hyperparams'\n",
    "# step2: return the best predictions using the best hyterparameters\n",
    "def get_best_preds(df_,   #df_heir_train\n",
    "                   cat_id  #cat_id in oneshop_cat_list \n",
    "                  ):\n",
    "    #get dataframe\n",
    "    columns = ['ds', cat_id]\n",
    "    df = df_.loc[:, columns]\n",
    "    df.columns = ['ds', 'y']\n",
    "    \n",
    "    #get best_params\n",
    "    best_params = get_best_hyperparams(df)\n",
    "    \n",
    "    #create model based on best_params\n",
    "    m = Prophet(changepoint_prior_scale=best_params['changepoint_prior_scale'], \n",
    "                seasonality_prior_scale=best_params['seasonality_prior_scale'], \n",
    "                yearly_seasonality=True)\n",
    "    m.add_country_holidays(country_name='RU')\n",
    "    m.fit(df)\n",
    "\n",
    "    #predict and return\n",
    "    future = m.make_future_dataframe(periods=1, freq='MS')\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(3))\n",
    "    fig1 = m.plot(forecast)\n",
    "    plt.show()\n",
    "\n",
    "    best_preds = forecast.tail(1).yhat.values[0]\n",
    "    print('best_preds: ', best_preds)\n",
    "    return best_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5606bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99dba6d1",
   "metadata": {},
   "source": [
    "# import data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fa15df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dict2 = pickle.load(open('../temp/data2.pkl', 'rb'))\n",
    "df_basegrid = pickle_dict2['df_basegrid']   #concat df_train_m and df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff6b6cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 10, 12, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 28, 31, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59]\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "list_shop_id=sorted(df_basegrid['shop_id'].unique())\n",
    "print(list_shop_id)\n",
    "print(len(list_shop_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a15872",
   "metadata": {},
   "source": [
    "# create hierachical time series for all shops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87519143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [07:28<00:00, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in tqdm(range(len(list_shop_id))):\n",
    "    ################ get one shop dataframe\n",
    "    #################################################################\n",
    "    df_oneshop = df_basegrid[df_basegrid['shop_id'] == list_shop_id[i]]\n",
    "\n",
    "    ##change values in the following columns so that their combinations are more readable\n",
    "    df_oneshop['date_block_num'] =df_oneshop['date_block_num'].astype(str)\n",
    "    df_oneshop['item_category_id'] =df_oneshop['item_category_id'].astype(str)\n",
    "    df_oneshop['shop_id'] =df_oneshop['shop_id'].astype(str)\n",
    "    df_oneshop['item_id'] =df_oneshop['item_id'].astype(str)\n",
    "    df_oneshop['item_category_id'] = 'c' + df_oneshop['item_category_id']\n",
    "    df_oneshop['shop_id'] = 's' + df_oneshop['shop_id']\n",
    "    df_oneshop['item_id'] = 'i' + df_oneshop['item_id']\n",
    "\n",
    "\n",
    "\n",
    "    ############### create hierachical time series for the shop\n",
    "    ##############################################################\n",
    "    level_names = ['item_category_id','item_id']\n",
    "    hierarchy = [['item_category_id']]\n",
    "    df_hier, sum_mat, sum_mat_labels = hts.functions.get_hierarchichal_df(df_oneshop,\n",
    "                                                                          level_names=level_names,\n",
    "                                                                          hierarchy=hierarchy,\n",
    "                                                                          date_colname='year_month',\n",
    "                                                                          val_colname='item_cnt_month')\n",
    "    #fill all null value with 0\n",
    "    df_hier = df_hier.fillna(0)\n",
    "    df_hier['ds']= df_hier.index\n",
    "\n",
    "    old_column_list = df_hier.columns\n",
    "    new_column_list = [old_column_list[-1], *old_column_list[:-1]]\n",
    "    df_hier = df_hier[new_column_list]\n",
    "\n",
    "    \n",
    "    ################ get the hier_dict\n",
    "    #################################################################\n",
    "\n",
    "    #get the lists\n",
    "    oneshop_cat_list = sorted(df_oneshop['item_category_id'].unique())\n",
    "    oneshop_item_list = sorted(df_oneshop['item_id'].unique())\n",
    "\n",
    "    #dictionary to hold all level nodes\n",
    "    hier_dict = {}\n",
    "\n",
    "    #get level 1 nodes: category nodes\n",
    "    level_1_nodes = [str(cat_id) for cat_id in oneshop_cat_list]\n",
    "\n",
    "    #print(level_1_nodes)\n",
    "    hier_dict['total'] = level_1_nodes\n",
    "\n",
    "    #get level 2 nodes\n",
    "    df_hier_columns = sorted(df_hier.columns)\n",
    "    for node in level_1_nodes: \n",
    "        temp_level_2_nodes = list(filter(lambda cat_item: f'{node}_' in cat_item, df_hier_columns))\n",
    "        hier_dict[node] = temp_level_2_nodes\n",
    "\n",
    "    tree = HierarchyTree.from_nodes(hier_dict, df_hier, root='total')\n",
    "    #print(tree)\n",
    "\n",
    "    sum_mat, sum_mat_labels = hts.functions.to_sum_mat(tree)\n",
    "\n",
    "\n",
    "\n",
    "    ###########save neccessary object to pickle_dict, \n",
    "    ############################################################################\n",
    "    pickle_dict_oneshop = dict()\n",
    "    pickle_dict_oneshop['df_hier']=df_hier   #concat df_train_m and df_test\n",
    "    pickle_dict_oneshop['tree']=tree \n",
    "    pickle_dict_oneshop['sum_mat']=sum_mat\n",
    "    pickle_dict_oneshop['sum_mat_labels']=sum_mat_labels\n",
    "    pickle_dict_oneshop['oneshop_cat_list']=oneshop_cat_list\n",
    "    pickle_dict_oneshop['oneshop_item_list']=oneshop_item_list\n",
    "\n",
    "    pickle.dump(pickle_dict_oneshop, open(f'../temp/s{list_shop_id[i]}_hier.pkl', 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17f33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8d339d0",
   "metadata": {},
   "source": [
    "# forecasting all hierarchical time series using prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b3d18b",
   "metadata": {},
   "source": [
    "### shop_id: 36 only has one month data, won't be fed into forcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2246b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 10, 12, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 28, 31, 34, 35, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59]\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "list_shop_id_filtered = list_shop_id.copy()\n",
    "list_shop_id_filtered.remove(36)\n",
    "print(list_shop_id_filtered)\n",
    "print(len(list_shop_id_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd75ab",
   "metadata": {},
   "source": [
    "### forecasting total sales and each category sales in each shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "for shop_id in tqdm(list_shop_id_filtered):\n",
    "    \n",
    "    print(f'\\n\\nforecasting shop: s{shop_id}')\n",
    "    \n",
    "    ####read one shop data from pickle_dict\n",
    "    #############################################\n",
    "    pickle_dict_oneshop = pickle.load(open(f'../temp/s{shop_id}_hier.pkl', 'rb'))\n",
    "    df_hier  = pickle_dict_oneshop['df_hier']\n",
    "    tree = pickle_dict_oneshop['tree']\n",
    "    sum_mat = pickle_dict_oneshop['sum_mat']\n",
    "    sum_mat_labels =pickle_dict_oneshop['sum_mat_labels']\n",
    "    oneshop_cat_list = pickle_dict_oneshop['oneshop_cat_list']\n",
    "    oneshop_item_list = pickle_dict_oneshop['oneshop_item_list']\n",
    "\n",
    "\n",
    "    ################### creat train, validation,and test dataset\n",
    "    ###########################################################################\n",
    "    df_hier_train = df_hier.loc[df_hier.index <= '2015-10-01']\n",
    "    df_hier_test = df_hier.loc[df_hier.index == '2015-11-01']\n",
    "\n",
    "\n",
    "    \n",
    "    forecasts = pd.DataFrame(columns = df_hier.columns, index=['fake'])\n",
    "    \n",
    "    \n",
    "    ################### forecasting total sales in this shop\n",
    "    #################################################################\n",
    "    print('\\ngetting best preds for forecast_total_sales')\n",
    "    forecasts['total'] = [get_best_preds(df_hier_train, 'total')]\n",
    "\n",
    "    \n",
    "  \n",
    "    ################### forecasting all category sales in this shop\n",
    "    #################################################################\n",
    "    #dataframe to hold the forecasts\n",
    "    for cat in oneshop_cat_list:\n",
    "        print(f'\\ngetting best preds for s{shop_id}_', cat)\n",
    "        forecasts[cat] = [get_best_preds(df_hier_train, cat)]\n",
    "\n",
    "\n",
    "    ###########save neccessary object to pickle_dict, \n",
    "    ############################################################################\n",
    "    pickle_dict_oneshop_new = dict()\n",
    "    pickle_dict_oneshop_new['forecasts']=forecasts\n",
    "    pickle.dump(pickle_dict_oneshop_new, open(f'../temp/s{shop_id}_forecasts.pkl', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87842006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9335c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
